{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a1e611-84aa-4744-86a1-5eb192eb9bed",
   "metadata": {},
   "source": [
    "Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322ba52a-2d7f-46d8-9485-c52c287ec009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: torch in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from transformers) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from transformers) (0.24.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (1.78.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (3.13.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: click in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: typer>=0.24.0 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from typer-slim->transformers) (0.24.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\chand_xiu5rxo\\anaconda3\\lib\\site-packages (from typer>=0.24.0->typer-slim->transformers) (0.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch tensorflow scikit-learn nltk networkx matplotlib pandas PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd46f6c0-db56-4858-b86b-902364b76871",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d9e301-4db1-47a5-ae19-51945f92ebd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chand_xiu5rxo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import PyPDF2\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d9249e-c0cb-4720-a47b-88c83383b91c",
   "metadata": {},
   "source": [
    "Text Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79863175-0b98-4b92-8da6-13337e143a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered = [w for w in words if w not in stop_words]\n",
    "    return \" \".join(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e61b33-0644-42a3-8a4b-99cba0b0e7e5",
   "metadata": {},
   "source": [
    "PDF Text Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "575056bb-3cbb-490c-a6c4-8ed62176fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \" \"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f8e8c9-61ed-494e-b980-0bfa0abaaedd",
   "metadata": {},
   "source": [
    "Experience Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3ace768-5dd6-49bc-8d3d-92d9fcd6d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_experience(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    patterns = [\n",
    "        r'(\\d+)\\+?\\s*years',\n",
    "        r'(\\d+)\\+?\\s*yrs',\n",
    "        r'(\\d+)\\+?\\s*year'\n",
    "    ]\n",
    "\n",
    "    experience_years = []\n",
    "\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        for match in matches:\n",
    "            experience_years.append(int(match))\n",
    "\n",
    "    if experience_years:\n",
    "        return max(experience_years)\n",
    "    else:\n",
    "        return \"Not Found\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bbe151-d612-491e-97da-bf2311cc6aa6",
   "metadata": {},
   "source": [
    "Load Dataset & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c89303-f772-44e9-a5cb-7406e4f9b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"all_job_post.csv\")\n",
    "\n",
    "df[\"job_description\"] = df[\"job_description\"].apply(clean_text).apply(remove_stopwords)\n",
    "df[\"skills\"] = df[\"job_skill_set\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "\n",
    "texts = df[\"job_description\"].tolist()\n",
    "labels = df[\"skills\"].tolist()\n",
    "\n",
    "tokenizer_lstm = Tokenizer(num_words=10000)\n",
    "tokenizer_lstm.fit_on_texts(texts)\n",
    "\n",
    "sequences = tokenizer_lstm.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen=150)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e43e6ad3-2ad7-450e-9d38-919876ad7e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR\n",
      "INFORMATION-TECHNOLOGY\n",
      "SALES\n",
      "FINANCE\n",
      "BUSINESS-DEVELOPMENT\n"
     ]
    }
   ],
   "source": [
    "for cat in df[\"category\"].unique():\n",
    "    print(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb151d8-5b22-45fe-93a4-3c78f5297d64",
   "metadata": {},
   "source": [
    "BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a6d7db4-11c7-4484-b8d8-a9456224fdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 137ms/step - auc: 0.5333 - loss: 0.4973 - val_auc: 0.6796 - val_loss: 0.0206\n",
      "Epoch 2/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - auc: 0.6947 - loss: 0.0197 - val_auc: 0.7386 - val_loss: 0.0202\n",
      "Epoch 3/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - auc: 0.7705 - loss: 0.0179 - val_auc: 0.7784 - val_loss: 0.0179\n",
      "Epoch 4/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - auc: 0.7978 - loss: 0.0162 - val_auc: 0.7877 - val_loss: 0.0173\n",
      "Epoch 5/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 138ms/step - auc: 0.7991 - loss: 0.0158 - val_auc: 0.7845 - val_loss: 0.0172\n",
      "Epoch 6/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - auc: 0.7949 - loss: 0.0158 - val_auc: 0.7820 - val_loss: 0.0173\n",
      "Epoch 7/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 138ms/step - auc: 0.7947 - loss: 0.0158 - val_auc: 0.7832 - val_loss: 0.0174\n",
      "Epoch 8/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 137ms/step - auc: 0.7942 - loss: 0.0158 - val_auc: 0.7826 - val_loss: 0.0175\n",
      "Epoch 9/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - auc: 0.7929 - loss: 0.0158 - val_auc: 0.7818 - val_loss: 0.0176\n",
      "Epoch 10/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - auc: 0.7928 - loss: 0.0158 - val_auc: 0.7835 - val_loss: 0.0176\n",
      "Epoch 11/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - auc: 0.7933 - loss: 0.0158 - val_auc: 0.7824 - val_loss: 0.0176\n",
      "Epoch 12/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - auc: 0.7938 - loss: 0.0158 - val_auc: 0.7828 - val_loss: 0.0177\n",
      "Epoch 13/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - auc: 0.7943 - loss: 0.0158 - val_auc: 0.7827 - val_loss: 0.0177\n",
      "Epoch 14/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - auc: 0.7947 - loss: 0.0158 - val_auc: 0.7832 - val_loss: 0.0178\n",
      "Epoch 15/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - auc: 0.7942 - loss: 0.0158 - val_auc: 0.7828 - val_loss: 0.0178\n",
      "Epoch 16/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - auc: 0.7932 - loss: 0.0158 - val_auc: 0.7824 - val_loss: 0.0179\n",
      "Epoch 17/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - auc: 0.7957 - loss: 0.0158 - val_auc: 0.7831 - val_loss: 0.0179\n",
      "Epoch 18/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - auc: 0.7927 - loss: 0.0158 - val_auc: 0.7828 - val_loss: 0.0179\n",
      "Epoch 19/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 138ms/step - auc: 0.7948 - loss: 0.0158 - val_auc: 0.7827 - val_loss: 0.0180\n",
      "Epoch 20/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - auc: 0.7938 - loss: 0.0158 - val_auc: 0.7822 - val_loss: 0.0180\n",
      "Epoch 21/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - auc: 0.7932 - loss: 0.0158 - val_auc: 0.7824 - val_loss: 0.0180\n",
      "Epoch 22/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - auc: 0.7933 - loss: 0.0158 - val_auc: 0.7825 - val_loss: 0.0180\n",
      "Epoch 23/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - auc: 0.7948 - loss: 0.0158 - val_auc: 0.7833 - val_loss: 0.0180\n",
      "Epoch 24/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - auc: 0.7933 - loss: 0.0158 - val_auc: 0.7839 - val_loss: 0.0181\n",
      "Epoch 25/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - auc: 0.7937 - loss: 0.0158 - val_auc: 0.7843 - val_loss: 0.0181\n",
      "Epoch 26/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - auc: 0.7956 - loss: 0.0158 - val_auc: 0.7827 - val_loss: 0.0181\n",
      "Epoch 27/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 168ms/step - auc: 0.7938 - loss: 0.0158 - val_auc: 0.7831 - val_loss: 0.0181\n",
      "Epoch 28/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 137ms/step - auc: 0.7939 - loss: 0.0158 - val_auc: 0.7831 - val_loss: 0.0181\n",
      "Epoch 29/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - auc: 0.7953 - loss: 0.0158 - val_auc: 0.7825 - val_loss: 0.0182\n",
      "Epoch 30/30\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - auc: 0.7957 - loss: 0.0158 - val_auc: 0.7823 - val_loss: 0.0182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25a42ac0c20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(150,)))\n",
    "model.add(Embedding(input_dim=10000, output_dim=128))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(y.shape[1], activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[tf.keras.metrics.AUC(name=\"auc\")]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50974fc4-84be-4556-a42b-9da78ba9cea0",
   "metadata": {},
   "source": [
    "Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a96682-400f-4562-b07c-c5abfc3af53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_skills_bilstm(job_text, threshold=0.4):\n",
    "    job_text = clean_text(job_text)\n",
    "    job_text = remove_stopwords(job_text)\n",
    "\n",
    "    seq = tokenizer_lstm.texts_to_sequences([job_text])\n",
    "    X_input = pad_sequences(seq, maxlen=150)\n",
    "\n",
    "    pred = model.predict(X_input)[0]\n",
    "    predicted_skills = [mlb.classes_[i] for i, val in enumerate(pred) if val > threshold]\n",
    "\n",
    "    return predicted_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28e0add-14b7-4266-852b-648880fe5a99",
   "metadata": {},
   "source": [
    "Master Skill Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d799a4-742d-440e-bdbf-3f9a4798030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_SKILLS = {\n",
    "\n",
    "    # Programming Languages\n",
    "    \"python\",\"java\",\"c++\",\"c#\",\"javascript\",\"typescript\",\"go\",\"rust\",\"scala\",\"kotlin\",\n",
    "    \"php\",\"ruby\",\"swift\",\"r\",\"matlab\",\"perl\",\"bash\",\"powershell\",\n",
    "\n",
    "    # Web Development\n",
    "    \"html\",\"css\",\"react\",\"angular\",\"vue\",\"next.js\",\"node.js\",\"express\",\"django\",\"flask\",\n",
    "    \"spring\",\"spring boot\",\"laravel\",\"asp.net\",\"jquery\",\"bootstrap\",\"tailwind\",\n",
    "\n",
    "    # Databases\n",
    "    \"sql\",\"mysql\",\"postgresql\",\"oracle\",\"mongodb\",\"redis\",\"cassandra\",\"dynamodb\",\n",
    "    \"firebase\",\"sqlite\",\"neo4j\",\"mariadb\",\"elasticsearch\",\n",
    "\n",
    "    # Cloud Platforms\n",
    "    \"aws\",\"azure\",\"gcp\",\"google cloud\",\"amazon web services\",\"microsoft azure\",\n",
    "    \"ec2\",\"s3\",\"lambda\",\"cloudformation\",\"iam\",\"rds\",\"eks\",\n",
    "    \"azure data factory\",\"adf\",\"azure devops\",\"azure functions\",\"blob storage\",\n",
    "    \"bigquery\",\"cloud run\",\"cloud functions\",\n",
    "\n",
    "    # DevOps Tools\n",
    "    \"docker\",\"kubernetes\",\"terraform\",\"ansible\",\"jenkins\",\"gitlab\",\"github actions\",\n",
    "    \"ci/cd\",\"devops\",\"helm\",\"prometheus\",\"grafana\",\"nagios\",\n",
    "\n",
    "    # Data Engineering\n",
    "    \"etl\",\"elt\",\"data pipeline\",\"data pipelines\",\"airflow\",\"apache airflow\",\n",
    "    \"spark\",\"pyspark\",\"hadoop\",\"hive\",\"pig\",\"kafka\",\"databricks\",\"snowflake\",\n",
    "    \"redshift\",\"synapse\",\"delta lake\",\n",
    "\n",
    "    # Machine Learning / AI\n",
    "    \"machine learning\",\"deep learning\",\"nlp\",\"computer vision\",\"pytorch\",\"tensorflow\",\n",
    "    \"keras\",\"scikit-learn\",\"xgboost\",\"opencv\",\"huggingface\",\"bert\",\"llm\",\n",
    "    \"langchain\",\"rag\",\"genai\",\"generative ai\",\n",
    "\n",
    "    # Cybersecurity\n",
    "    \"cyber security\",\"penetration testing\",\"ethical hacking\",\"network security\",\n",
    "    \"cryptography\",\"siem\",\"splunk\",\"firewall\",\"ids\",\"ips\",\"vulnerability assessment\",\n",
    "\n",
    "    # Mobile Development\n",
    "    \"android\",\"ios\",\"flutter\",\"react native\",\"swiftui\",\"kotlin android\",\n",
    "\n",
    "    # Testing / QA\n",
    "    \"selenium\",\"cypress\",\"junit\",\"pytest\",\"automation testing\",\"manual testing\",\n",
    "    \"testng\",\"postman\",\"api testing\",\n",
    "\n",
    "    # Tools / Version Control\n",
    "    \"git\",\"github\",\"bitbucket\",\"jira\",\"confluence\",\"linux\",\"unix\",\"windows\",\n",
    "    \"visual studio\",\"vscode\",\"intellij\",\"eclipse\",\n",
    "\n",
    "    # Networking\n",
    "    \"tcp/ip\",\"dns\",\"http\",\"https\",\"vpn\",\"routing\",\"switching\",\n",
    "\n",
    "    # Analytics\n",
    "    \"power bi\",\"tableau\",\"excel\",\"data analysis\",\"data visualization\",\"looker\",\n",
    "\n",
    "    # Others\n",
    "    \"microservices\",\"rest api\",\"graphql\",\"soap\",\"system design\",\"distributed systems\",\n",
    "    \"oop\",\"data structures\",\"algorithms\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ea0cb-cf48-42e1-840b-349d354a6a31",
   "metadata": {},
   "source": [
    "Rule-Based Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03563cf1-c705-4518-80e7-2513e17887f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def universal_skill_extractor(text):\n",
    "    text = text.lower()\n",
    "    found_skills = [skill for skill in MASTER_SKILLS if skill in text]\n",
    "    return sorted(list(set(found_skills)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221fac28-db57-4465-8cab-dac549160101",
   "metadata": {},
   "source": [
    "Final Skill Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ee96ff6-1b83-461c-9e4e-df088615d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_skill_extractor(job_desc):\n",
    "    bilstm_skills = predict_skills_bilstm(job_desc, threshold=0.4)\n",
    "    rule_skills = universal_skill_extractor(job_desc)\n",
    "    final_skills = list(set(bilstm_skills + rule_skills))\n",
    "    return sorted(final_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38fda355-4819-455d-9acf-becb2c49c574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\n",
      "âœ… Extracted Skills:\n",
      "['azure', 'azure data factory', 'communication', 'data pipeline', 'data pipelines', 'databricks', 'etl', 'problem solving', 'python', 'r', 'spark', 'sql']\n"
     ]
    }
   ],
   "source": [
    "test_jd = \"\"\"\n",
    "Looking for a Data Engineer with strong Python, SQL, ETL, Azure Data Factory, Spark, Databricks and data pipelines experience.\n",
    "\"\"\"\n",
    "\n",
    "skills_found = final_skill_extractor(test_jd)\n",
    "\n",
    "print(\"\\nâœ… Extracted Skills:\")\n",
    "print(skills_found)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8479351b-f412-472c-a0aa-943efe912f38",
   "metadata": {},
   "source": [
    "Resume Input + Full Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88dd1eac-318e-4845-9f10-b272b31673c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Resume PDF Path:  C:\\Users\\chand_xiu5rxo\\Downloads\\Sales-Executive-Resume.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\n",
      "âœ… Extracted Skills:\n",
      "['communication', 'excel', 'go', 'ips', 'problem solving', 'r', 'rag']\n",
      "\n",
      "ğŸ“Š Total Experience (Years):\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "pdf_path = input(\"Enter Resume PDF Path: \")\n",
    "\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "skills_found = final_skill_extractor(resume_text)\n",
    "experience_years = extract_experience(resume_text)\n",
    "\n",
    "print(\"\\nâœ… Extracted Skills:\")\n",
    "print(skills_found)\n",
    "\n",
    "print(\"\\nğŸ“Š Total Experience (Years):\")\n",
    "print(experience_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca8a864-ecae-4df4-8df1-320c67151388",
   "metadata": {},
   "source": [
    "Save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9ecf6f8-75ad-4f7b-8212-525402d1a0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model, Tokenizer, MLB and Config saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create folder to store model files\n",
    "os.makedirs(\"saved_model\", exist_ok=True)\n",
    "\n",
    "# 1ï¸âƒ£ Save BiLSTM Model\n",
    "model.save(\"saved_model/bilstm_skill_model.h5\")\n",
    "\n",
    "# 2ï¸âƒ£ Save Tokenizer\n",
    "with open(\"saved_model/tokenizer_lstm.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer_lstm, f)\n",
    "\n",
    "# 3ï¸âƒ£ Save MultiLabelBinarizer\n",
    "with open(\"saved_model/mlb.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mlb, f)\n",
    "\n",
    "# 4ï¸âƒ£ Save sequence length (IMPORTANT)\n",
    "with open(\"saved_model/config.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"maxlen\":150}, f)\n",
    "\n",
    "print(\"âœ… Model, Tokenizer, MLB and Config saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
